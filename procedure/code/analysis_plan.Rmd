---
title: "Analysis Plan Version 1"
author: "Samuel Barnard and Matthew Mills"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs") })
nocite: '@*'
bibliography: "../../software.bib"
---

# Abstract

This study is a *reproduction* of: Tuholske, C., Lynch, V.D., Spriggs, R.
et al.
Hazardous heat exposure among incarcerated people in the United States.
*Nat Sustain 7*, 394â€“398 (2024).
<https://doi.org/10.1038/s41893-024-01293-y> [Git Repository](https://github.com/sparklabnyc/temperature_prisons_united_states_2024)

By reproducing the exploratory data analysis done in Tuholske et al. (2024), we seek to...

*1.* Identify the temporal resolution at which authors use population data to calculate population weighted hazardous heat days

*2.* Understand the population weighting mechanism in state-level hazardous heat calculations.

*3.* Evaluate the effectiveness of the author's methods compared to similar research.

# Study metadata

-   `Key words`: Comma-separated list of keywords (tags) for searchability. Geographers often use one or two keywords each for: theory, geographic context, and methods.
-   `Subject`: Social and Behavioral Sciences: Geography: Geographic Information Sciences, Human Geography, Nature and Society Relations
-   `Date created`: 04/14/25
-   `Date modified`: 04/21/25
-   `Spatial Coverage`: United States Lower 48
-   `Spatial Resolution`: Carceral facility points and States
-   `Spatial Reference System`: Specify the geographic or projected coordinate system for the study, e.g. EPSG:4326
-   `Temporal Coverage`: 1982-2020
-   `Temporal Resolution`: 1 year

## Original study spatio-temporal metadata

-   `Spatial Coverage`: United States Lower 48
-   `Spatial Resolution`: Carceral facility points and States
-   `Spatial Reference System`: spatial reference system of original study
-   `Temporal Coverage`: 1982-2020
-   `Temporal Resolution`: 1 year

# Study design

This study is a **reproduction study**, and the original study is more **exploratory** in design.
The primary objective for exploration through research and analysis investigated in the original study was exposure to hazardous heat in carceral facilities in the continental U.S.
The authors wanted to examine how exposure to hazardous heat changed over time from 1982-2020, as well as how exposure within carceral facilities compared to exposure in the rest of the state.
In general, determining the spatial distribution of carceral facilities with higher levels of hazardous heat exposure was also an objective of the original paper

# Materials and procedure

## Computational environment

### Original study computational environment

The original study data transformations and analysis were completed primarily in R using Rmd documents, as well as in Python.
The versions of R and Python used are not disclosed, but would have been R 4.3.3 or earlier, and Python 3.12 or earlier.

In the original study, R packages are called in across different scripts.
However, it seems that the important ones for this study are:

```{r eval=FALSE}
original_study_packages <- c(
  "dplyr", 
  "data.table", 
  "maptools",
  "mapproj",
  "rgeos",
  "rgdal",
  "RColorBrewer",
  "ggplot2",
  "raster", # planned deviation: we will be using `stars` in our reproduction
  "sp", # planned deviation: we will be using `sf` in our reproduction
  "plyr",
  "graticule",
  "zoo",
  "purrr",
  "cowplot",
  "janitor"
  )
```

### Prepare reproduction computational environment

For the reproduction study, we will be using R version 4.4.2, and the `groundhog` package to maintain package consistency.
All packages used will be up to date as of 2025-02-01.

We plan on using the packages `tidyverse`, `here`, `markdown`, `htmltools`, `dplyr`, `sf`, and `stars`.
As we encounter the need for other packages in our implimentation of the code, we will make note of them as unplanned deviations.

```{r environment-setup, include = FALSE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c("tidyverse", "here", "markdown", "htmltools", "dplyr", "sf", "stars")

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)

# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2025-02-01"

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day,
                  tolerate.R.version='4.4.2')
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = FALSE, # Show outputs, but not code. Change to TRUE to show code as well
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)
```

## Data and variables

We are going to use data from the original study's git repository (linked on top level readme).
This includes:

\- Population data for the study period

\- Prison boundary polygons with facility information

\- State polygons

\- WBGT data, at prison point and state levels

### Population Data

```{r}
includeMarkdown(
  here("data", "metadata", "metadata_population.md")
)
```

### Prison Boundaries

```{r}
includeMarkdown(
  here("data", "metadata", "metadata_Prison_Boundaries.md")
)
```

### State Boundaries

```{r}
includeMarkdown(
  here("data", "metadata", "metadata_statesshp.md")
)
```

### WBGT Data

#### WBGT Data - Prison Level

```{r}
includeMarkdown(
  here("data", "metadata", "metadata_wbgt_prison.md")
)
```

#### WBGT Data - State Level

```{r}
includeMarkdown(
  here("data", "metadata", "metadata_wbgt_state.md")
)
```

## Prior observations

At the time of this pre-analysis plan, we have the derived data to work off of, and we have examined some of the csv tables.
We have neither visualized nor analyzed prison data or WBGTmax temperature data before.

## Bias and threats to validity

There are no statistical tests in this study, so issues such as spatial heterogeneity/anistropy/autocorrelation do not matter.
Scale could be a threat to validity, because county populations are aggregated to calculate the number of population-weighted heat days in each state.
There is also a scale issue measuring micro-climate conditions at prison boundaries compared to 4 km temperature data.
Further, there is no specification of how heat days are calculated within each county given that counties do no map neatly to 4 km by 4km grids used to calculate hazardous heat days.
The ways in which the county boundaries are drawn also supports the argument that there is a Modifiable Area Unit Problem.

Both the scale and boundary issues also have a temporal component that may create threats to validity.

## Data transformations

### Planned deviation:

We will not attempt to produce the original study's WBGTmax grid because the methods are unclear, and therefore we will skip to joining the author-provided WBGTmax by day grid data to the prison points.

(When implementing plan) Explain what we believe the authors did to produce the WBGTmax grid and preliminary steps

### Transform data to create Figures 1a, 1b

(More descriptive segment of original study's workflow)

# OFFICE HOURS NOTES
recount the hazardous heat days (summarize hazardous heat excedence) per year by prison
# heat excedence by prison and year
#NOTES- sequencing is unclear, first round of regressions is done in data rangling, HAVE TO READ ALL OF THE CODE AND SUPPLEMENTARY MATRIALS AND THE PAPER 2b is in the wrangling, 2c is calcued in the actual figure 2 code

#### Step 1: Join author-provided WBGTmax by day grid data to author-provided carceral facility point data

*Unplanned Deviation:* Step 1: Read in WBGTmax by prison data as single RDS frame.

(This step takes a while to run!)

Code is adapted from original repository

```{r}
# Define years
start_year_wbgt <- 1982
end_year_wbgt <- 2020
years_wbgtmax <- c(start_year_wbgt:end_year_wbgt)

raw_wbgt_prison_data <- here("data", "raw", "public", "wbgt_raw", "prison", "")
raw_wbgt_state_data <- here("data", "raw", "public", "wbgt_raw", "state", "")

# Create data frame

dat.all = data.frame()
for(year in years_wbgtmax){
  print(paste0('Loading ',year))
  dat.current = readRDS(paste0(raw_wbgt_prison_data,'weighted_area_raster_prison_wbgtmax_daily_',year,'.rds'))
  dat.all= data.table::rbindlist(list(dat.all,dat.current))
  print(paste0('Loaded ',year))
}

saveRDS(dat.all,paste0(
  here("data", "derived", "private", ""), # quotation marked added based on assumption, moved file manually
  'weighted_area_raster_prison_wbgtmax_daily_',start_year_wbgt,'_',end_year_wbgt,'.rds'))

```

*Unplanned Deviation:* Data still needs to be joined to prison points

*Result:* Rds table of WBGTmax by day by prison

#### Step 2: Filter result by days when WBGTmax exceeded 28 degrees C

```{r}
# read in WBGT prisons file
wbgtmax_prison <- readRDS(here("data", "derived", "private", "weighted_area_raster_prison_wbgtmax_daily_1982_2020.rds"))

# summarize by different temp. thresholds
dat.wbgt.summarised = wbgtmax_prison %>%
  mutate(wbgt_26=ifelse(wbgtmax>26,1,0),wbgt_28=ifelse(wbgtmax>28,1,0),
         wbgt_30=ifelse(wbgtmax>30,1,0),wbgt_35=ifelse(wbgtmax>35,1,0)) %>%
  group_by(prison_id, year) %>%
  dplyr::summarise(wbgt_26=sum(wbgt_26), wbgt_28=sum(wbgt_28), wbgt_30=sum(wbgt_30), wbgt_35=sum(wbgt_35))

saveRDS(dat.wbgt.summarised,here("data", "derived", "private", "dat.wbgt.summarised.rds"))
```

*Unplanned Deviation:* Try and pivot <-- I don't think we need to do this. If we pivot wide, we won't be able to summarize hazardous heat days with a group by

```{r}
dat.wbgt.summarised |> pivot_wider(
  names_from = year,
  values_from = wbgt_28
)
```

#### Step 3: Group by carceral facility type and year
The group by is already included in the study's filter/summary code from 02 --MM
Count to produce summary of days exceeded per year by facility

*Result:* Rds table with variables\
- prison facility

\- facility type

\- prison population

\- n days exceeding 28 degrees

\- year

*Unplanned Deviation:*
**Taken from original code
## Take Number of days in first year, last year and last 5 years of data
# prepares data for figure 1 and figure 2b (and a little bit for 2c) --MM
```{r}
dat.wbgt.summarised.start = dat.wbgt.summarised %>%
  dplyr::filter(year%in%c(start_year_wbgt)) %>%
  dplyr::select(-year) %>%
  dplyr::rename_with(~ paste0(., "_", start_year_wbgt), -prison_id)

dat.wbgt.summarised.end = dat.wbgt.summarised %>%
  dplyr::filter(year%in%c(end_year_wbgt)) %>%
  dplyr::select(-year) %>%
  dplyr::rename_with(~ paste0(., "_", end_year_wbgt), -prison_id)

dat.wbgt.summarised.last.5 = dat.wbgt.summarised %>%
  dplyr::filter(year%in%c((end_year_wbgt-4):end_year_wbgt)) %>%
  group_by(prison_id) %>%
  summarise(wbgt_26=mean(wbgt_26),
            wbgt_28=mean(wbgt_28),
            wbgt_30=mean(wbgt_30),
            wbgt_35=mean(wbgt_35)) %>%
  dplyr::rename_with(~ paste0(., "_", as.numeric(end_year_wbgt-4), "_", end_year_wbgt), -prison_id)
```

## Trends in growth of number of day per year over time
# totals are calculated by multiplying the regression slope by the total number of years -MM
```{r}
dat.wbgt.summarised.regression.26 = dat.wbgt.summarised %>%
  mutate(year=as.numeric(year)) %>%
  group_by(prison_id) %>%
  do(broom::tidy(lm(wbgt_26 ~ year, data = .))) %>%
  dplyr::filter(term=='year') %>%
  select(prison_id,estimate) %>%
  mutate(total_change_wbgt_26=estimate*(length(years_wbgtmax))) %>%
  rename(annual_change_wbgt_26=estimate) %>%
  select(prison_id,annual_change_wbgt_26,total_change_wbgt_26)

dat.wbgt.summarised.regression.28 = dat.wbgt.summarised %>%
  mutate(year=as.numeric(year)) %>%
  group_by(prison_id) %>%
  do(broom::tidy(lm(wbgt_28 ~ year, data = .))) %>%
  dplyr::filter(term=='year') %>%
  select(prison_id,estimate) %>%
  mutate(total_change_wbgt_28=estimate*(length(years_wbgtmax))) %>%
  rename(annual_change_wbgt_28=estimate) %>%
  select(prison_id,annual_change_wbgt_28,total_change_wbgt_28)

dat.wbgt.summarised.regression.30 = dat.wbgt.summarised %>%
  mutate(year=as.numeric(year)) %>%
  group_by(prison_id) %>%
  do(broom::tidy(lm(wbgt_30 ~ year, data = .))) %>%
  dplyr::filter(term=='year') %>%
  select(prison_id,estimate) %>%
  mutate(total_change_wbgt_30=estimate*(length(years_wbgtmax))) %>%
  rename(annual_change_wbgt_30=estimate) %>%
  select(prison_id,annual_change_wbgt_30,total_change_wbgt_30)

dat.wbgt.summarised.regression.35 = dat.wbgt.summarised %>%
  mutate(year=as.numeric(year)) %>%
  group_by(prison_id) %>%
  do(broom::tidy(lm(wbgt_35 ~ year, data = .))) %>%
  dplyr::filter(term=='year') %>%
  select(prison_id,estimate) %>%
  mutate(total_change_wbgt_35=estimate*(length(years_wbgtmax))) %>%
  rename(annual_change_wbgt_35=estimate) %>%
  select(prison_id,annual_change_wbgt_35,total_change_wbgt_35)
```

## Merge regression analyses into one data frame
```{r}
dat.wbgt.summarised.regression.merged = left_join(dat.wbgt.summarised.start,dat.wbgt.summarised.end) %>%
  left_join(.,dat.wbgt.summarised.last.5) %>%
  left_join(.,dat.wbgt.summarised.regression.26) %>%
  left_join(.,dat.wbgt.summarised.regression.28) %>%
  left_join(.,dat.wbgt.summarised.regression.30) %>%
  left_join(.,dat.wbgt.summarised.regression.35)
```

## Save regression file
```{r}
# original code
saveRDS(dat.wbgt.summarised.regression.merged,paste0(wbgt.folder,'weighted_area_raster_prison_wbgtmax_daily_',start_year_wbgt,'_',end_year_wbgt,'_regression_analysis.rds'))

# our code
saveRDS(dat.wbgt.summarised,here("data", "derived", "private", "dat.wbgt_regression_analysis.rds"))
```

#### Step 4: combine state level WBGT data into a single file

## Iterate across years of WBGT data and combine into one large file
```{r}
dat.all = data.frame()
for(year in years_wbgtmax){
  print(paste0('Loading ',year))
  dat.current = readRDS(paste0(raw_wbgt_state_data,'weighted_area_raster_fips_wbgtmax_daily_',year,'.rds'))
  dat.all= data.table::rbindlist(list(dat.all,dat.current))
  print(paste0('Loaded ',year))
}

saveRDS(dat.all,paste0(
  here("data", "derived", "private", ""), # quotation marked added based on assumption, moved file manually
  'weighted_area_raster_state_wbgtmax_daily_',start_year_wbgt,'_',end_year_wbgt,'.rds'))
```

#### Step 4b: summarize hazardous heat day count by county

```{r}
wbgtmax_state <- readRDS(here("data", "derived", "private", "weighted_area_raster_state_wbgtmax_daily_1982_2020.rds"))

# code from original study
dat.wbgt.state.summarised = wbgtmax_state %>%
  mutate(wbgt_26=ifelse(wbgtmax>26,1,0),wbgt_28=ifelse(wbgtmax>28,1,0),
         wbgt_30=ifelse(wbgtmax>30,1,0),wbgt_35=ifelse(wbgtmax>35,1,0)) %>%
  group_by(fips, year) %>%
  dplyr::summarise(wbgt_26=sum(wbgt_26), wbgt_28=sum(wbgt_28), wbgt_30=sum(wbgt_30), wbgt_35=sum(wbgt_35)) %>%
  mutate(fips=as.character(fips))

saveRDS(dat.wbgt.state.summarised,here("data", "derived", "private", "dat.wbgt.state.summarised.rds"))
```

*Unplanned Deviation:*
Per original study, fix counties to be consistent all the way through

```{r}
dat.wbgt.state.summarised = dat.wbgt.state.summarised %>%
      mutate(fips = case_when(
        fips== '08001' | fips== '08013' | fips== '08059' | fips== '08123' ~ '08014', # 08001, 08013, 08059, 08123 -> 08014
        fips== '12025' ~ '12086', #  12025 -> 12086
        fips== '30031' | fips== '30067'~ '30113', # 30113 -> 30031, 30067
        fips== '46113' ~ '46102', # 46113 -> 46102
        fips== '51560' ~ '51005', # 51560 -> 51005
        fips== '51780' ~ '51083', # 51780 -> 51083
        fips== '51515' ~ '51019', # 51515 -> 51019
        TRUE ~ fips
        ))
```

Next, summarize by the fixed counties

```{r}
dat.wbgt.state.summarised = dat.wbgt.state.summarised %>%
  group_by(fips, year) %>%
  dplyr::summarise(wbgt_26=mean(wbgt_26),wbgt_28=mean(wbgt_28),wbgt_30=mean(wbgt_30),wbgt_35=mean(wbgt_35))
```

#### Step 4c: load county populations

```{r}
# original study code
dat_pop= data.frame()
for(year_selected in years_wbgtmax){
  if(year_selected<1990){
    filename_in = paste0(here("data", "raw", "public", "population", "pre_1990", ""),
                         'pop_monthly_10_year_age_groups_', year_selected,'.csv')  
  }
  if(year_selected>=1990){
    filename_in = paste0(here("data", "raw", "public", "population", "vintage_2020", ""),
                         'pop_monthly_10_year_age_groups_',year_selected,'.csv')
  }
  dat_year=readr::read_csv(filename_in)
  dat_pop = data.table::rbindlist(list(dat_pop,dat_year))
  rm(dat_year)
}

dat_pop = dat_pop %>%
  dplyr::filter(month==6) %>%
  dplyr::group_by(year,fips) %>%
  dplyr::summarise(pop=sum(pop))
```

#### Step 4d: join population data with summarized, county-level hazardous heat data

```{r}
# original study code
dat.wbgt.state.summarised.merged = left_join(dat.wbgt.state.summarised,dat_pop)
dat.wbgt.state.summarised.merged.na = dat.wbgt.state.summarised.merged %>% dplyr::filter(is.na(pop)==TRUE)

saveRDS(dat.wbgt.state.summarised.merged,here("data", "derived", "private", "dat.wbgt.state.summarised.merged.rds"))
```

*Unplanned Deviation:* Report list of counties with NA population values.

```{r}
dat.wbgt.state.summarised.merged.na
```

Join to county shapefiles

Filter entire dataset by those fips and see if they have population data
dplyr filter where fips is %IN% group of fips code

Take average of year before and year after
dplyr filter where fips is in group of fips code, and in year 2011 and 2013
group by average of pop

#### Step 4e: 

## Analysis

### Analyze data to create Figures 2a, 2b and 2c

Figure 2b, 2c - results are based on linear regression models

#### Step 4: Begin with result from Step 3

#### Step 5: Spatial join county population by year data

*Result:* Rds table with variables\
- prison facility

\- facility type

\- prison population

\- county

\- population

\- n days exceeding 28 degrees

\- year

#### Step 6: Population-weighted aggregation

Aggregate data into states

Weighted sum of days exceeded across all counties of the state

Sum of days exceeded multiplied by (Ratio of county population / state population)

## Planned deviations for reproduction:

### Deviation 1: Investigating temperature threshold

Repeat workflow for reproducing figures 1 and 2, instead filtering for days when WBGTmax exceeded 29.4 degrees C (85 degrees F standard informed by other literature)

### Deviation 2: Investigating sources of uncertainty/error/bias

#### How many open facilities had a population of -999? (Potential source of uncertainty)

#### Step 7: Select facilities with population of -999 from author-provided carceral facilities data.

Report number of facilities compared to authors' number.

# Results: Present figures (reproduced from original study and planned deviations).

## Create Fig. 1a and b using results from step 3

### Make Figure 1a

*Unplanned Deviation:* Attempt to work through author's code for Figure 1

```{r}
dat.wbgt.summarised.regression = readRDS(here("data", "derived", "private", "dat.wbgt_regression_analysis.rds"))
```


## Create Fig. 2a, b and c using results from step 6

## Map result from step 7 to examine data quality issue

# Discussion

What are the implications of us being able to recreate or not recreate the figures?
Why does it matter for the original study to be reproducible?
Mention significance of groundhog usage for sustainable reproduction.
Discuss research suggesting maximum daily temperature doesn't matter as much for heat stress, and how long stretches of night time lows may be more serious.

# Integrity Statement

This is the first version of our pre-analysis plan.
Any deviations in our workflow will be documented as unplanned deviations.

# Acknowledgements

This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, [DOI:[10.17605/OSF.IO/W29MQ](DOI:%5B10.17605/OSF.IO/W29MQ){.uri}](https://doi.org/10.17605/OSF.IO/W29MQ)

## References

> Kedron, P., & Holler, J.
> (2023).
> Template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences.
> <https://doi.org/10.17605/OSF.IO/W29MQ>
